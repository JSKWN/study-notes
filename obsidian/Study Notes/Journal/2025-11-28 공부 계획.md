---
title: 2025-11-28
date: 2025-11-28
categories:
  - Daily Notes
tags: []
keywords: []
---
- [[#해야할 공부 (찾아 봐야 할 것)|해야할 공부 (찾아 봐야 할 것)]]
- [[#기타|기타]]

> 오늘 할일 (개인 용무)
> - 방송대 기출문제 프린트


## 해야할 공부 (찾아 봐야 할 것)
---
1. 비전 모델 Task 별 '방법론' 및 '모델 구조' 파악 
	- classification, segmentation, object detection 등 흐름 파악 필요
	- 모델만 있는게 아니라, '모델과 알고리즘이 결합한 형태'인지 정리
2. 텐서플로우 기능 파악 필요 
	- Layer, Model 클래스 상속 및 기능 파악
	- build, get_config 메서드, tf 버전 의존성 등 문제 파악
	- 모델 구조 구현해볼때, 주석 달면서 내용도 함께 정리
3. 2개 이상의 모델을 연계하는 방식의 예시를 찾아봐야함
	- LLM의 경우는 멀티에이전트가 있음. Vision 모델 등에서도 이러한 방식을 활용하는지?
	- Vision 모델의 일반적인 연계 방법?

## 작성해 볼 코드?
- 모델 성능 개선을 위한 방법들
	- Reasoning
	- MoE
	- 강화학습
	- 학습전략
	- Distillation
	- MoE

## 기타
---
- 데이터 전처리 및 분석 방법 정리 (트렌드 파악)
- Re-identification? VLA?
- 최적화 및 경량화 방법 정리 (코드로 해야함)
	- Quantization
	- Pruning
	- Knowledge Distilation
- 클래스 불균형 대응
- 정량 지표 해석 (mAP/IOU/F1)
- 2D/3D vision 실사용 방법
- 추론 모델(reasoning) 기법: CoT, ToT 등
- 강화학습 → vision 모델의 경우 NAS(신경망 아키텍처 탐색)이 가장 잘 어울릴듯
- 학습 전략 (커리큘럼 러닝)


뭐부터 시작하지? 우선은 2개 이상 모델 연계 방안..

- Compound AI systems 라고 부르는듯
- 에이전트(Agent)에 대한 내용도 탐색 필요
	- 왜 필요하다고 생각? → 멀티 에이전트의 경우 여러개의 모델 활용

Distillation을 하려면, 기존에 학습된 공개된 작은 규모의 LLM 앞뒷단에 CNN 레이어를 붙인 후 추론하게 하면 안되나?

### CoT(Chain-of-Thought) 정리
---
> 요약
> - 다음 토큰을 예측하기 위해 현재 컨텍스트(Context)를 더 유리하게 조작
> - 사고 과정(thinking 등)에서 사용된 토큰들은 압축 또는 제거하여 활용

- LLM은 조건부 확률 분포인데, 주어진 입력 X에 대해 정답 Y를 내놓을 때, 모델은 한번에 Y를 뱉는게 아니라, 토큰 단위로 확률을 계산함. (단어장에 있는 모든 단어에 대한 확률을 계산한 후, 한 개의 토큰만 반환)
- 하지만 X가 복잡한 논리가 포함된 경우, 중간 과정 없이 바로 정답 Y를 예측하게 되면, 확률 분포가 평평해지거나 엉뚱한 토큰에 높은 확률을 배정(Hallucination)하게됨
	- 예: CoT 없이 바로 답을 내야 할 때
		- “23 * 14는?”이라는 질문에 대해 확률이 균등한 경우 존재
			- P("322") = 0.15
			- P("312") = 0.14
		    - P("332") = 0.13
	- 예: CoT로 중간 과정을 거쳤을 때
		- 질문이 "20×14=280이고, 3×14=42이므로, 합하면?" 이라는 방식으로 변형됨 → 확률을 유추하기 쉬움
- 문제 해결을 위한 중간 사고 과정을 단계적으로 활용




